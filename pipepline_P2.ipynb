{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /home/w4z3/.local/lib/python3.10/site-packages (4.3.3)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/w4z3/.local/lib/python3.10/site-packages (from pymongo) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /home/w4z3/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/w4z3/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/w4z3/.local/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/w4z3/.local/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/w4z3/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo\n",
    "%pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, when, isnull, lower, regexp_replace, array_contains, explode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECONCILIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ParquetReadExample\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "##################################################################################################\n",
    "#                                        LOAD DATAFRAMES\n",
    "##################################################################################################\n",
    "# LOOKUP TABLES - IDEALISTA\n",
    "df_rent_district_lookup = spark.read.json(\"./P2_data/lookup_tables/rent_lookup_district.json\")\n",
    "df_rent_neighborhood_lookup = spark.read.json(\"./P2_data/lookup_tables/rent_lookup_neighborhood.json\")\n",
    "\n",
    "# LOOKUP TABLES - INCOME_OPENDATA\n",
    "df_income_district_lookup = spark.read.json(\"./P2_data/lookup_tables/income_lookup_district.json\")\n",
    "df_income_neighborhood_lookup = spark.read.json(\"./P2_data/lookup_tables/income_lookup_neighborhood.json\")\n",
    "\n",
    "# IDEALISTA PARQUET FILES\n",
    "parquetDF = spark.read.parquet(\"./P2_data/idealista/*/*\")\n",
    "#parquetDF.filter(parquetDF[\"municipality\"] == 'Barcelona').show()\n",
    "\n",
    "# INCOME_OPENDATA JSON\n",
    "openData_df = spark.read.json(\"./P2_data/income_opendata/income_opendata_neighborhood.json\")\n",
    "\n",
    "# THIRD DATASET: SQUAREMETERPRICEEVOLUTION JSON\n",
    "squaremeterpriceevolution_df = spark.read.json(\"./P2_data/SquareMeterPriceEvolution/squareMeterPriceEvolution.json\")\n",
    "##################################################################################################\n",
    "\n",
    "##################################################################################################\n",
    "#                                        RECONCILIATION\n",
    "##################################################################################################\n",
    "# IDEALISTA\n",
    "idealista_reconciled_df = None\n",
    "if \"district\" in parquetDF.columns and all(col_name in df_rent_district_lookup.columns for col_name in [\"di\", \"di_n\", \"di_re\"]):\n",
    "        df1 = parquetDF.alias(\"df1\")\n",
    "        df2 = df_rent_district_lookup.alias(\"df2\")\n",
    "\n",
    "        # Join the DataFrames based on matching conditions\n",
    "        joined_df = df1.join(df2, (col(\"df1.district\") == col(\"df2.di\")) | (col(\"df1.district\") == col(\"df2.di_n\")) | (col(\"df1.district\") == col(\"df2.di_re\")), \"left_outer\") \\\n",
    "                        .select(\"df1.*\", col(\"df2._id\").alias(\"district_id\"), \"df2.di_re\")\n",
    "\n",
    "        # Replace the values in the \"district\" column with \"di_re\" values from df2\n",
    "        idealista_reconciled_df = joined_df.withColumn(\"district\", when(col(\"di_re\").isNotNull(), col(\"di_re\")).otherwise(col(\"district\"))) \\\n",
    "                   .drop(\"di_re\")\n",
    "        \n",
    "if \"neighborhood\" in idealista_reconciled_df.columns and all(col_name in df_rent_neighborhood_lookup.columns for col_name in [\"ne\", \"ne_n\", \"ne_re\"]):\n",
    "        df1 = idealista_reconciled_df.alias(\"df1\")\n",
    "        df2 = df_rent_neighborhood_lookup.alias(\"df2\")\n",
    "\n",
    "        # Join the DataFrames based on matching conditions\n",
    "        joined_df = df1.join(df2, (col(\"df1.neighborhood\") == col(\"df2.ne\")) | (col(\"df1.neighborhood\") == col(\"df2.ne_n\")) | (col(\"df1.neighborhood\") == col(\"df2.ne_re\")), \"left_outer\") \\\n",
    "                        .select(\"df1.*\", col(\"df2._id\").alias(\"neighborhood_id\"), \"df2.ne_re\")\n",
    "\n",
    "        # Replace the values in the \"district\" column with \"ne_re\" values from df2\n",
    "        idealista_reconciled_df = joined_df.withColumn(\"neighborhood\", when(col(\"ne_re\").isNotNull(), col(\"ne_re\")).otherwise(col(\"neighborhood\"))) \\\n",
    "                   .drop(\"ne_re\")\n",
    "\n",
    "#idealista_reconciled_df.show()\n",
    "\n",
    "# INCOME_OPENDATA\n",
    "incomeOpenData_reconciled_df = None\n",
    "if \"district_name\" in openData_df.columns and all(col_name in df_income_district_lookup.columns for col_name in [\"district\", \"district_name\", \"district_reconciled\"]):\n",
    "        df1 = openData_df.alias(\"df1\")\n",
    "        df2 = df_income_district_lookup.alias(\"df2\")\n",
    "\n",
    "        # Join the DataFrames based on matching conditions\n",
    "        joined_df = df1.join(df2, (col(\"df1.district_name\") == col(\"df2.district\")) | (col(\"df1.district_name\") == col(\"df2.district_name\")) | (col(\"df1.district_name\") == col(\"df2.district_reconciled\")), \"left_outer\") \\\n",
    "                        .select(\"df1.*\", col(\"df2._id\").alias(\"districtID\"), \"df2.district_reconciled\")\n",
    "\n",
    "        # Replace the values in the \"district\" column with \"district_reconciled\" values from df2\n",
    "        incomeOpenData_reconciled_df = joined_df.withColumn(\"district_name\", when(col(\"district_reconciled\").isNotNull(), col(\"district_reconciled\")).otherwise(col(\"district_name\"))).drop(\"district_reconciled\")\n",
    "\n",
    "if \"neigh_name \" in incomeOpenData_reconciled_df.columns and all(col_name in df_income_neighborhood_lookup.columns for col_name in [\"neighborhood\", \"neighborhood_name\", \"neighborhood_reconciled\"]):\n",
    "        df1 = incomeOpenData_reconciled_df.alias(\"df1\")\n",
    "        df2 = df_income_neighborhood_lookup.alias(\"df2\")\n",
    "\n",
    "        # Join the DataFrames based on matching conditions\n",
    "        joined_df = df1.join(df2, (col(\"df1.neigh_name \") == col(\"df2.neighborhood\")) | \n",
    "                                        (col(\"df1.neigh_name \") == col(\"df2.neighborhood_name\")) | \n",
    "                                        (col(\"df1.neigh_name \") == col(\"df2.neighborhood_reconciled\")) | \n",
    "                                        (col(\"df1.neigh_name \") == regexp_replace(col(\"df2.neighborhood_reconciled\"), \"\\\"\", \"\")), \"left_outer\")\\\n",
    "                        .select(\"df1.*\", col(\"df2._id\").alias(\"neighborhoodID\"), \"df2.neighborhood_reconciled\")\n",
    "    \n",
    "        # Replace the values in the \"district\" column with \"neighborhood_reconciled\" values from df2\n",
    "        incomeOpenData_reconciled_df = joined_df.withColumn(\"neigh_name \", when(col(\"neighborhood_reconciled\").isNotNull(), col(\"neighborhood_reconciled\")).otherwise(col(\"neigh_name \"))).drop(\"neighborhood_reconciled\")\n",
    "\n",
    "# REPORT: drop inutil cols, Remove \"\\\"\" to not keep nulls! ERROR?\n",
    "incomeOpenData_reconciled_df = incomeOpenData_reconciled_df.drop(incomeOpenData_reconciled_df.columns[0]).drop(incomeOpenData_reconciled_df.columns[1])\n",
    "incomeOpenData_reconciled_df = incomeOpenData_reconciled_df.select(incomeOpenData_reconciled_df.districtID.alias(\"district_id\"),\n",
    "                                                                        incomeOpenData_reconciled_df.district_name.alias(\"district\"),\n",
    "                                                                        incomeOpenData_reconciled_df.neighborhoodID.alias(\"neighborhood_id\"),\n",
    "                                                                        incomeOpenData_reconciled_df['neigh_name '].alias(\"neighborhood\"),\n",
    "                                                                        incomeOpenData_reconciled_df.info)\n",
    "\n",
    "\n",
    "#incomeOpenData_reconciled_df.show()\n",
    "\n",
    "# SQUAREMETERPRICEEVOLUTION                                                         \n",
    "squareMeterPriceEvolution_reconciled_df = None\n",
    "\n",
    "if \"neighborhood\" in squaremeterpriceevolution_df.columns and all(col_name in df_income_neighborhood_lookup.columns for col_name in [\"neighborhood\", \"neighborhood_name\", \"neighborhood_reconciled\"]):\n",
    "        df1 = squaremeterpriceevolution_df.alias(\"df1\")\n",
    "        df2 = df_income_neighborhood_lookup.alias(\"df2\")\n",
    "\n",
    "        # Join the DataFrames based on matching conditions\n",
    "        joined_df = df1.join(df2, (lower(col(\"df1.neighborhood\")) == lower(col(\"df2.neighborhood\"))) | \n",
    "                                        (lower(col(\"df1.neighborhood\")) == lower(col(\"df2.neighborhood_name\"))) | \n",
    "                                        (lower(col(\"df1.neighborhood\")) == lower(col(\"df2.neighborhood_reconciled\"))) | \n",
    "                                        (lower(col(\"df1.neighborhood\")) == lower(regexp_replace(col(\"df2.neighborhood_reconciled\"), \"\\\"\", \"\"))), \"left_outer\")\\\n",
    "                        .select(\"df1.*\", col(\"df2._id\").alias(\"neighborhoodID\"), \"df2.neighborhood_reconciled\")\n",
    "    \n",
    "        # Replace the values in the \"district\" column with \"di_re\" values from df2\n",
    "        squareMeterPriceEvolution_reconciled_df = joined_df.withColumn(\"neighborhood\", when(col(\"neighborhood_reconciled\").isNotNull(), col(\"neighborhood_reconciled\")).otherwise(col(\"neighborhood\"))).drop(\"neighborhood_reconciled\")\n",
    "\n",
    "\n",
    "squareMeterPriceEvolution_reconciled_df = squareMeterPriceEvolution_reconciled_df.join(df_income_district_lookup, array_contains(df_income_district_lookup.neighborhood_id, squareMeterPriceEvolution_reconciled_df.neighborhoodID), \"left\")\n",
    "squareMeterPriceEvolution_reconciled_df = squareMeterPriceEvolution_reconciled_df.select(squareMeterPriceEvolution_reconciled_df._id.alias(\"district_id\"),\n",
    "                                                                        squareMeterPriceEvolution_reconciled_df.district,\n",
    "                                                                        squareMeterPriceEvolution_reconciled_df.neighborhoodID.alias(\"neighborhood_id\"),\n",
    "                                                                        squareMeterPriceEvolution_reconciled_df.neighborhood,\n",
    "                                                                        squareMeterPriceEvolution_reconciled_df.info)\n",
    "\n",
    "#squareMeterPriceEvolution_reconciled_df.show()\n",
    "##################################################################################################\n",
    "\n",
    "##################################################################################################\n",
    "#                                        DEDUPLICATION\n",
    "##################################################################################################\n",
    "\n",
    "# Do not remove duplicated by propertyCode because in other analysis may be interesting see the evolution of price for the same property related to certain factors like seasonality\n",
    "idealista_deduplicated_df = idealista_reconciled_df.dropDuplicates()\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "##################################################################################################\n",
    "#                                   FORMATTING & FILTERING & EXPANDING\n",
    "##################################################################################################\n",
    "\n",
    "idealista_filtered_df = idealista_deduplicated_df.filter(col(\"price\").isNotNull())\n",
    "idealista_filtered_df = idealista_filtered_df.filter(idealista_filtered_df[\"price\"] > 0)\n",
    "idealista_filtered_df = idealista_filtered_df.withColumn(\"address\", regexp_replace(col(\"address\"), \"Calle de \", \"C/ \"))\n",
    "idealista_filtered_df = idealista_filtered_df.withColumn(\"address\", regexp_replace(col(\"address\"), \"Calle dels \", \"C/ \"))\n",
    "idealista_filtered_df = idealista_filtered_df.withColumn(\"address\", regexp_replace(col(\"address\"), \"Calle \", \"C/ \"))\n",
    "idealista_filtered_df = idealista_filtered_df.withColumn(\"address\", regexp_replace(col(\"address\"), \"barrio\", \"Barrio\"))\n",
    "\n",
    "incomeOpenData_expanded_df = incomeOpenData_reconciled_df.select(\"district_id\", \"district\", \"neighborhood_id\", \"neighborhood\", explode(\"info\").alias(\"info\"))\n",
    "incomeOpenData_expanded_df = incomeOpenData_expanded_df.select(\"district_id\", \"district\", \"neighborhood_id\", \"neighborhood\", \"info.year\", \"info.pop\", \"info.RFD\")\n",
    "#incomeOpenData_expanded_df.show()\n",
    "\n",
    "squareMeterPriceEvolution_expanded_df = squareMeterPriceEvolution_reconciled_df.select(\"district_id\", \"district\", \"neighborhood_id\", \"neighborhood\", explode(\"info\").alias(\"info\"))\n",
    "squareMeterPriceEvolution_expanded_df = squareMeterPriceEvolution_expanded_df.select(\"district_id\", \"district\", \"neighborhood_id\", \"neighborhood\", \"info.year\", \"info.preu_m2\")\n",
    "#squareMeterPriceEvolution_expanded_df.show()\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "##################################################################################################\n",
    "#                                        SAVE AS PARQUET FILES\n",
    "##################################################################################################\n",
    "\n",
    "idealista_filtered_df.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\", \"snappy\").partitionBy(\"neighborhood_id\").save(\"./distributedFolder/idealista\")\n",
    "incomeOpenData_expanded_df.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\", \"snappy\").partitionBy(\"neighborhood_id\").save(\"./distributedFolder/incomeOpenData\")\n",
    "squareMeterPriceEvolution_expanded_df.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\", \"snappy\").partitionBy(\"neighborhood_id\").save(\"./distributedFolder/squareMeterPriceEvolution\")\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df2008 = pd.read_csv(\"./P2_data/SquareMeterPriceEvolution/DOSZEROZEROVUIT_SquareMeterPriceEvolution.csv\")\n",
    "df2008['BARRIS'] = df2008['BARRIS'].str.replace(r'^\\d+\\.\\s+', '')\n",
    "df2009 = pd.read_csv(\"./P2_data/SquareMeterPriceEvolution/DOSZEROZERONOU_SquareMeterPriceEvolution.csv\")\n",
    "df2009['BARRIS'] = df2009['BARRIS'].str.replace(r'^\\d+\\.\\s+', '')\n",
    "df2010 = pd.read_csv(\"./P2_data/SquareMeterPriceEvolution/DOSZERODEU_SquareMeterPriceEvolution.csv\")\n",
    "df2010['BARRIS'] = df2010['BARRIS'].str.replace(r'^\\d+\\.\\s+', '')\n",
    "df2011 = pd.read_csv(\"./P2_data/SquareMeterPriceEvolution/DOSZEROONZE_SquareMeterPriceEvolution.csv\")\n",
    "df2011['BARRIS'] = df2011['BARRIS'].str.replace(r'^\\d+\\.\\s+', '')\n",
    "\n",
    "newDict = []\n",
    "\n",
    "df_json = df2008.to_json(orient='records')\n",
    "data = json.loads(df_json)\n",
    "for neig in data:\n",
    "    newDict.append({'neighborhood': neig['BARRIS'], 'info': [{'year': 2008, 'preu_m2': neig['PREU_M2']}]})\n",
    "\n",
    "df_json = df2009.to_json(orient='records')\n",
    "data = json.loads(df_json)\n",
    "for neig in data:\n",
    "    for entry in newDict:\n",
    "        if neig['BARRIS'] == entry['neighborhood']:\n",
    "            entry['info'].append({'year': 2009, 'preu_m2': neig['PREU_M2']})\n",
    "\n",
    "df_json = df2010.to_json(orient='records')\n",
    "data = json.loads(df_json)\n",
    "for neig in data:\n",
    "    for entry in newDict:\n",
    "        if neig['BARRIS'] == entry['neighborhood']:\n",
    "            entry['info'].append({'year': 2010, 'preu_m2': neig['PREU_M2']})\n",
    "\n",
    "df_json = df2011.to_json(orient='records')\n",
    "data = json.loads(df_json)\n",
    "for neig in data:\n",
    "    for entry in newDict:\n",
    "        if neig['BARRIS'] == entry['neighborhood']:\n",
    "            entry['info'].append({'year': 2011, 'preu_m2': neig['PREU_M2']})\n",
    "\n",
    "with open(\"./P2_data/SquareMeterPriceEvolution/squareMeterPriceEvolution.json\", 'w') as json_file:\n",
    "    for dictionary in newDict:\n",
    "        json_file.write(str(dictionary).replace(\"'\",'\"') + '\\n')\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
